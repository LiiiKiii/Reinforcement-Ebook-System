Source: arXiv
URL: http://arxiv.org/abs/2306.11113v2

==================================================

论文标题: Learn to Accumulate Evidence from All Training Samples: Theory and Practice
作者: Deep Pandey, Qi Yu
摘要: Evidential deep learning, built upon belief theory and subjective logic, offers a principled and computationally efficient way to turn a deterministic neural network uncertainty-aware. The resultant evidential models can quantify fine-grained uncertainty using the learned evidence. To ensure theoretically sound evidential models, the evidence needs to be non-negative, which requires special activation functions for model training and inference. This constraint often leads to inferior predictive performance compared to standard softmax models, making it challenging to extend them to many large-scale datasets. To unveil the real cause of this undesired behavior, we theoretically investigate evidential models and identify a fundamental limitation that explains the inferior performance: existing evidential activation functions create zero evidence regions, which prevent the model to learn from training samples falling into such regions. A deeper analysis of evidential activation functions ...
arXiv链接: http://arxiv.org/abs/2306.11113v2
请访问链接查看完整论文。