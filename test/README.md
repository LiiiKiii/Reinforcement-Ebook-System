## AI-Pedia 测试总览

本目录用于对现有系统进行 **定性 + 定量** 测试，包括：

- 性能测试（每个核心技术/模块）
- 主观评价（用户打分）
- 客观指标（自动统计的可量化指标）

先通读本文件，再根据需要进入子目录补充具体测试数据。

目录结构：

- `performance/`：性能测试脚本（`run_performance_tests.py`），用于自动化测试
- `evaluation_subjective/`：主观评价（易用性、满意度等问卷或打分）
- `evaluation_objective/`：客观指标（包含性能指标和质量指标的完整说明和表格模板）

---

### 1. 核心测试维度

至少覆盖以下几个维度（可以根据需要增减）：

- **技术维度**：关键词提取、资源搜索、CBF 推荐、AI 摘要等
- **性能维度**：响应时间 / 吞吐量 / 失败率 / 稳定性 / 资源占用
- **体验维度**：可用性、易理解程度、结果满意度
- **鲁棒性维度**：对不同类型数据的适应性、异常输入处理等

---

### 2. 各子目录说明

- `performance/`：包含可直接运行的性能测试脚本（`run_performance_tests.py`）  
- `evaluation_subjective/`：问卷设计、主观评价表格模板  
- `evaluation_objective/`：客观指标完整说明（包含性能指标和质量指标的定义、公式、表格模板和图表建议）

---

### 3. 需要补充的内容

- **数据集/测试文本**：提供代表性强的测试文档或数据集路径
- **测试环境说明**：CPU / 内存 / 操作系统 / Python 版本等
- **主观评价问卷结果**：将用户/专家的打分填入模板
- **客观指标统计结果**：在跑完脚本后，把输出的数字抄写/整理成表格

### 4. 实验思路

- 定量
  - 主观
    - 对各技术分别进行测试，输入分别为(如下)，结果将以表格或图例的形式呈现
      - 少量AI相关的不同方向的资源
      - 大量AI相关的不同方向的资源
      - 少量AI相关的同一方向的资源
      - 大量AI相关的同一方向的资源
      
    - 每次测验/调整时只关注一个技术，确保其独立性，所有文件将在evaluation_objective文件夹中
      - 使用对该技术评估常用的标准方法进行测评
      - 
  
  - 客观
    - 以问卷形式收集用户反馈，评估系统在不同维度上的表现


      
- 定性
  - 对系统整体进行测试，输入分别为(如下)，需要为这些资源提前设置好关键词作为评价指标
    - 少量AI相关的不同方向的资源
    - 大量AI相关的不同方向的资源
    - 少量AI相关的同一方向的资源
    - 大量AI相关的同一方向的资源

    - 少量AI无关的不同方向的资源
    - 大量AI无关的不同方向的资源
    - 少量AI无关的同一方向的资源
    - 大量AI无关的同一方向的资源
 
  - 结果不再以特定评估方式测评，而使用更广泛的统计方式，评估系统的整体性能（如处理速度，关键词准确率，推荐内容相关性）