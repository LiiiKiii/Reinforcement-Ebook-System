## 主观评价测试说明（evaluation_subjective）

本目录用于设计和收集 **主观评价** 数据，主要由用户 / 专家通过问卷或打分的方式完成。

典型维度包括：

- **易用性**：界面友好程度、操作是否顺畅
- **理解度**：是否容易理解推荐结果/关键词/摘要的含义
- **满意度**：整体使用体验、推荐结果是否“有用”
- **信任度**：对系统输出结果的信任程度
- **创新感**：是否感觉到系统有技术/交互上的创新

---

### 1. 建议的问卷结构

可以以“李克特量表”（1–5分 或 1–7分）来设计问题，例如：

- Q1：系统界面是否易于理解和上手？（1=非常难用，5=非常易用）
- Q2：系统给出的关键词是否准确反映了文档内容？（1=非常不准确，5=非常准确）
- Q3：系统推荐的外部资源对你的学习是否有帮助？（1=完全没有帮助，5=非常有帮助）
- Q4：你对系统整体推荐结果的信任程度如何？（1=完全不信任，5=完全信任）
- Q5：你认为该系统在功能或交互上是否具有创新性？（1=完全没有，5=非常有）

可以根据论文/项目需要，自行设计更多问题。

---

### 2. 主观评价结果表格模板

建议按“被试/用户”为行，“问题”为列，例如：

| 受试者ID | 角色（学生/老师/研究者） | Q1 易用性 | Q2 关键词准确性 | Q3 推荐帮助度 | Q4 信任度 | Q5 创新感 | 备注 |
|----------|--------------------------|-----------|------------------|---------------|-----------|-----------|------|
| U01      | 学生                     |           |                  |               |           |           |      |
| U02      | 教师                     |           |                  |               |           |           |      |
| U03      | 研究者                   |           |                  |               |           |           |      |

收集到数据后，你可以在 Excel / 统计工具中计算：

- 每一题的 **平均值 / 标准差**
- 不同角色之间的差异（例如学生 vs 老师）
- 总体满意度的分布情况（柱状图/折线图）

---

### 3. 主观 vs 客观的对应关系（示例）

为了后续分析更清晰，可以在这里定义主观评价与客观指标的映射关系，例如：

- Q2「关键词准确性」 ↔ 客观上 `keyword_extractor` 的覆盖率/冗余度等指标
- Q3「推荐帮助度」 ↔ 客观上推荐资源的点击率 / 完成率等（若有日志）
- Q4「信任度」 ↔ 客观上错误率/异常情况统计

---

### 4. 需要准备的内容

- 问卷题目最终版本（可以写在一个单独的 `questionnaire.md` 中）
- 实际发放渠道（线上表单/纸质问卷等）
- 回收后的原始数据（可以导出为 CSV / Excel 然后填入上述表格模板）

